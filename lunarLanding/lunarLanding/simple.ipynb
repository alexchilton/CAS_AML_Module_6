{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Jupyter notebook sample"
   ],
   "id": "8a77807f92f26ee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T10:16:17.153861Z",
     "start_time": "2025-01-22T10:16:17.149136Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "import imageio\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch\n",
    "from agilerl.algorithms.td3 import TD3\n",
    "from agilerl.components.replay_buffer import ReplayBuffer\n",
    "from agilerl.hpo.mutation import Mutations\n",
    "from agilerl.hpo.tournament import TournamentSelection\n",
    "from agilerl.training.train_off_policy import train_off_policy\n",
    "#from agilerl.utils.utils import create_population, make_vect_envs\n",
    "from tqdm import trange"
   ],
   "id": "7df9140457caed5e",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "2e44cfe2f556cba1"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-22T10:16:20.449393Z",
     "start_time": "2025-01-22T10:16:20.442750Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initial hyperparameters\n",
    "INIT_HP = {\n",
    "    \"ALGO\": \"TD3\",\n",
    "    \"POP_SIZE\": 4,  # Population size\n",
    "    \"BATCH_SIZE\": 128,  # Batch size\n",
    "    \"LR_ACTOR\": 0.0001,  # Actor learning rate\n",
    "    \"LR_CRITIC\": 0.001,  # Critic learning rate\n",
    "    \"O_U_NOISE\": True,  # Ornstein-Uhlenbeck action noise\n",
    "    \"EXPL_NOISE\": 0.1,  # Action noise scale\n",
    "    \"MEAN_NOISE\": 0.0,  # Mean action noise\n",
    "    \"THETA\": 0.15,  # Rate of mean reversion in OU noise\n",
    "    \"DT\": 0.01,  # Timestep for OU noise\n",
    "    \"GAMMA\": 0.99,  # Discount factor\n",
    "    \"MEMORY_SIZE\": 100_000,  # Max memory buffer size\n",
    "    \"POLICY_FREQ\": 2,  # Policy network update frequency\n",
    "    \"LEARN_STEP\": 1,  # Learning frequency\n",
    "    \"TAU\": 0.005,  # For soft update of target parametersy\n",
    "    # Swap image channels dimension from last to first [H, W, C] -> [C, H, W]\n",
    "    \"CHANNELS_LAST\": False,  # Use with RGB states\n",
    "    \"EPISODES\": 1000,  # Number of episodes to train for\n",
    "    \"EVO_EPOCHS\": 20,  # Evolution frequency, i.e. evolve after every 20 episodes\n",
    "    \"TARGET_SCORE\": 200.0,  # Target score that will beat the environment\n",
    "    \"EVO_LOOP\": 3,  # Number of evaluation episodes\n",
    "    \"MAX_STEPS\": 500,  # Maximum number of steps an agent takes in an environment\n",
    "    \"LEARNING_DELAY\": 1000,  # Steps before starting learning\n",
    "    \"EVO_STEPS\": 10000,  # Evolution frequency\n",
    "    \"EVAL_STEPS\": None,  # Number of evaluation steps per episode\n",
    "    \"EVAL_LOOP\": 1,  # Number of evaluation episodes\n",
    "    \"TOURN_SIZE\": 2,  # Tournament size\n",
    "    \"ELITISM\": True,  # Elitism in tournament selection\n",
    "}\n",
    "\n",
    "# Mutation parameters\n",
    "MUT_P = {\n",
    "    # Mutation probabilities\n",
    "    \"NO_MUT\": 0.4,  # No mutation\n",
    "    \"ARCH_MUT\": 0.2,  # Architecture mutation\n",
    "    \"NEW_LAYER\": 0.2,  # New layer mutation\n",
    "    \"PARAMS_MUT\": 0.2,  # Network parameters mutation\n",
    "    \"ACT_MUT\": 0.2,  # Activation layer mutation\n",
    "    \"RL_HP_MUT\": 0.2,  # Learning HP mutation\n",
    "    # Learning HPs to choose from\n",
    "    \"RL_HP_SELECTION\": [\"lr\", \"batch_size\", \"learn_step\"],\n",
    "    \"MUT_SD\": 0.1,  # Mutation strength\n",
    "    \"RAND_SEED\": 42,  # Random seed\n",
    "    # Define max and min limits for mutating RL hyperparams\n",
    "    \"MIN_LR\": 0.0001,\n",
    "    \"MAX_LR\": 0.01,\n",
    "    \"MIN_BATCH_SIZE\": 8,\n",
    "    \"MAX_BATCH_SIZE\": 1024,\n",
    "    \"MIN_LEARN_STEP\": 1,\n",
    "    \"MAX_LEARN_STEP\": 16,\n",
    "}"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T10:20:40.980975Z",
     "start_time": "2025-01-22T10:20:40.949740Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from agilerl.utils.utils import make_vect_envs, create_population\n",
    "import torch"
   ],
   "id": "26d79b398cc06676",
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'make_vect_envs' from 'agilerl.utils.utils' (/opt/anaconda3/envs/lunarLanding/lib/python3.8/site-packages/agilerl/utils/utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01magilerl\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m make_vect_envs, create_population\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n",
      "\u001B[0;31mImportError\u001B[0m: cannot import name 'make_vect_envs' from 'agilerl.utils.utils' (/opt/anaconda3/envs/lunarLanding/lib/python3.8/site-packages/agilerl/utils/utils.py)"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "62a8c026dc794d85"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T10:16:25.234439Z",
     "start_time": "2025-01-22T10:16:25.207196Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "num_envs=8\n",
    "env = make_vect_envs(\"LunarLanderContinuous-v2\", num_envs=num_envs)  # Create environment\n",
    "try:\n",
    "    state_dim = env.single_observation_space.n, # Discrete observation space\n",
    "    one_hot = True  # Requires one-hot encoding\n",
    "except Exception:\n",
    "    state_dim = env.single_observation_space.shape  # Continuous observation space\n",
    "    one_hot = False  # Does not require one-hot encoding\n",
    "try:\n",
    "    action_dim = env.single_action_space.n  # Discrete action space\n",
    "except Exception:\n",
    "    action_dim = env.single_action_space.shape[0]  # Continuous action space\n",
    "\n",
    "INIT_HP[\"MAX_ACTION\"] = float(env.single_action_space.high[0])\n",
    "INIT_HP[\"MIN_ACTION\"] = float(env.single_action_space.low[0])\n",
    "\n",
    "if INIT_HP[\"CHANNELS_LAST\"]:\n",
    "    # Adjust dimensions for PyTorch API (C, H, W), for envs with RGB image states\n",
    "    state_dim = (state_dim[2], state_dim[0], state_dim[1])\n"
   ],
   "id": "e65e58a1b7e04493",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'make_vect_envs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m num_envs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m8\u001B[39m\n\u001B[0;32m----> 2\u001B[0m env \u001B[38;5;241m=\u001B[39m \u001B[43mmake_vect_envs\u001B[49m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLunarLanderContinuous-v2\u001B[39m\u001B[38;5;124m\"\u001B[39m, num_envs\u001B[38;5;241m=\u001B[39mnum_envs)  \u001B[38;5;66;03m# Create environment\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m      4\u001B[0m     state_dim \u001B[38;5;241m=\u001B[39m env\u001B[38;5;241m.\u001B[39msingle_observation_space\u001B[38;5;241m.\u001B[39mn, \u001B[38;5;66;03m# Discrete observation space\u001B[39;00m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'make_vect_envs' is not defined"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Set-up the device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Define the network configuration of a simple mlp with two hidden layers, each with 64 nodes\n",
    "net_config = {\"arch\": \"mlp\", \"hidden_size\": [64, 64]}\n",
    "\n",
    "# Define a population\n",
    "pop = create_population(\n",
    "    algo=\"TD3\",  # Algorithm\n",
    "    state_dim=state_dim,  # State dimension\n",
    "    action_dim=action_dim,  # Action dimension\n",
    "    one_hot=one_hot,  # One-hot encoding\n",
    "    net_config=net_config,  # Network configuration\n",
    "    INIT_HP=INIT_HP,  # Initial hyperparameters\n",
    "    population_size=INIT_HP[\"POP_SIZE\"],  # Population size\n",
    "    num_envs=num_envs,\n",
    "    device=device,\n",
    ")"
   ],
   "id": "71837cf980113e7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
